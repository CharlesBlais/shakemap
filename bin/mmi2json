#!/usr/bin/env python

# stdlib imports
import argparse
import os.path
import json
from collections import OrderedDict

# third party imports
from impactutils.io.table import read_excel

# local imports
from shakemap.utils.config import get_config_paths


def get_station_feature(row):
    scode = '%s.%s' % (row['NETID'], row['STATION'])
    station_feature = OrderedDict()
    station_properties = OrderedDict()
    station_feature['type'] = 'Feature'
    station_feature['id'] = scode
    station_properties['name'] = row['LOC']

    station_properties['code'] = row['STATION']
    station_properties['network'] = 'INTENSITY'
    if 'DISTANCE' in row:
        station_properties['distance'] = row['DISTANCE']

    # limit MMI to between 1-10
    if row['INTENSITY'] > 10.0:
        row['INTENSITY'] = 10.0
    if row['INTENSITY'] < 1.0:
        row['INTENSITY'] = 1.0
    station_properties['intensity'] = row['INTENSITY']
    station_properties['intensity_flag'] = row['FLAG']
    station_properties['intensity_stddev'] = 0.0
    # station_properties['source'] = stream[0].stats.standard['source']
    station_properties['source'] = row['SOURCE']
    station_properties['station_type'] = 'macroseismic'
    station_properties['channels'] = []

    station_feature['properties'] = station_properties
    coordinates = (row['LON'], row['LAT'])
    station_feature['geometry'] = {'type': 'Point',
                                   'coordinates': coordinates}
    return station_feature


def main():
    description = '''Import an Excel spreadsheet of MMI values.

    Input: Excel spreadsheet with the following REQUIRED columns:
     - STATION: Station code.
     - INTENSITY: MMI value between 1-10.
     - LAT: Latitude of observation.
     - LON: Longitude of observation.
     - LOC: Description of location of observation.
     - SOURCE: Description of source of observation.
     - NETID: Network that originated observation.
     - ELEV: Elevation of observation.
     - FLAG: Flag value (non-zero is bad).
    '''
    parser = argparse.ArgumentParser(description=description)
    parser.add_argument('eventid', metavar='EVENTID', help='Input eventid')
    parser.add_argument('file', metavar='FILE', help='Input spreadsheet')
    args = parser.parse_args()

    _, data_path = get_config_paths()
    datadir = os.path.join(data_path, args.eventid, 'current')
    if not os.path.isdir(datadir):
        os.makedirs(datadir)

    dataframe, reference = read_excel(args.file)
    _, fname = os.path.split(args.file)
    basename, _ = os.path.splitext(fname)
    jsonfile = os.path.join(datadir, basename + '_dat.json')

    features = []
    for idx, row in dataframe.iterrows():
        feature = get_station_feature(row)
        features.append(feature)

    jdict = {'type': 'FeatureCollection', 'features': features}

    with open(jsonfile, 'wt') as f:
        json.dump(jdict, f)
    print('Wrote %i records to %s' % (len(dataframe), jsonfile))


if __name__ == '__main__':
    main()
