#!/usr/bin/env python

# stdlib imports
import sys
import os.path
import shutil
import argparse
import datetime
import json

# third party imports
from libcomcat.search import get_event_by_id
from configobj import ConfigObj

# local imports
from shakemap.utils.config import get_config_paths
from shakelib.rupture.origin import write_event_file, Origin
from shakelib.rupture.factory import text_to_json, rupture_from_dict_and_origin
from shakemap.utils.utils import get_network_name

TIMEFMT = '%Y-%m-%dT%H:%M:%S.%fZ'


def get_parser():
    description = '''
    "Clone" a ShakeMap from NEIC Comcat, or create an event from scratch.

    Notes on usage:

    eventid is a ComCat event ID.  For example, for this event:
    https://earthquake.usgs.gov/earthquakes/eventpage/us2000ar20
    The event ID is us2000ar20.

    If no source is specified, then the event ID used for the event directory,
    eventid field in event.xml file, and names of data and fault files will
    be that of the *authoritative* origin.

    If a source (us, ci, nc, etc.) is specified, then that ID is used instead
    of the authoritative ID.


    '''
    formatter = argparse.RawDescriptionHelpFormatter
    parser = argparse.ArgumentParser(description=description,
                                     formatter_class=formatter)
    parser.add_argument('eventid',
                        help='ID of the event to process')
    parser.add_argument('-f', '--force', action='store_true',
                        help='Force overwrite of event data.')
    parser.add_argument('-s', '--source',
                        help='Specify the source network of desired shakemap.')
    parser.add_argument('-e', '--event',
                        help='Specify the event parameters: [netid, time, lon, lat, depth, mag].')
    parser.add_argument('-n', '--no-scenario', action='store_true', default=False,
                        help='When used with -e, disable scenario mode.')
    parser.add_argument('-p', '--preserve-params', action='store_true', default=False,
                        help='Preserve model parameters detected in ComCat.')
    return parser


def _get_event_dictionary(detail, source):
    edict = None

    if source is not None:
        # get basic event information from an origin contributed by input
        # source
        try:
            origin = detail.getProducts('origin', source=source)[0]
            eventid = source + origin['eventsourcecode']
            edict = {'id': eventid,
                     'netid': source,
                     'network': get_network_name(source),
                     'lat': float(origin['latitude']),
                     'lon': float(origin['longitude']),
                     'depth': float(origin['depth']),
                     'mag': float(origin['magnitude']),
                     'time': datetime.datetime.strptime(origin['eventtime'],
                                                        TIMEFMT),
                     'locstring': detail.location}
        except ValueError:
            print('No origin for event %s.' % source)
    else:  # no source specified, use detail object
        edict = {'id': detail.id,
                 'netid': detail['net'],
                 'network': get_network_name(detail['net']),
                 'lat': detail.latitude,
                 'lon': detail.longitude,
                 'depth': detail.depth,
                 'mag': detail.magnitude,
                 'time': detail.time,
                 'locstring': detail.location}
    return edict


def main(args):
    install_path, data_path = get_config_paths()
    if not os.path.isdir(data_path):
        print('%s is not a valid directory.' % data_path)
        sys.exit(1)

    if args.event:
        locstring = ''
        netid = args.event[0]
        timestr = args.event[1]
        time = HistoricTime.strptime(timestr, TIMEFMT)
        lon = args.event[2]
        lat = args.event[3]
        depth = args.event[4]
        mag = args.event[5]
        if len(args.event) > 6:
            locstring = args.event[6]

        network = get_network_name(netid)
        if network == 'unknown':
            network = ''

        eventid = args.eventid
        if args.no_scenario:
            if not args.eventid.endswith('_se'):
                eventid = eventid + '_se'

        edict = {'id': eventid,
                 'netid': netid,
                 'network': network,
                 'time': time,
                 'lat': lat,
                 'lon': lon,
                 'depth': depth,
                 'mag': mag,
                 'locstring': locstring}
        detail = None
    else:
        # Get the DetailEvent product for this event ID
        # regardless of input, the output directory and files
        # will contain the *authoritative* event ID from ComCat,
        # unless source is specified.
        detail = get_event_by_id(args.eventid)
        # get input data
        edict = _get_event_dictionary(detail, args.source)
        if edict is None:
            print('No event dictionary, quitting.')
            exit(1)
        eventid = edict['id']

    # check to see if the event directory exists
    event_dir = os.path.join(data_path, eventid, 'current')
    if not os.path.isdir(event_dir):
        os.makedirs(event_dir)
    else:
        if not args.force:
            print('Event directory %s already exists.  Use -f '
                  'option to overwrite.' % event_dir)
            sys.exit(1)
        shutil.rmtree(event_dir)
        os.makedirs(event_dir)

    # name the event.xml file
    event_xml_file = os.path.join(event_dir, 'event.xml')

    # write the event.xml file
    write_event_file(edict, event_xml_file)

    if detail is not None:
        # if this event has a shakemap, then we have more to do
        if not detail.hasProduct('shakemap'):
            print('Event %s has no ShakeMap product. Creating a basic ShakeMap.' %
                  detail.id)
        else:
            if args.source:
                source = args.source
            else:
                source = 'preferred'
            try:
                shakemap = detail.getProducts('shakemap', source=source)[0]
            except AttributeError:
                msg = 'No ShakeMap product from source %s exists.' % source
                print(msg)
                sys.exit(0)

            data_file = os.path.join(event_dir, '%s_dat.xml' % eventid)
            shakemap.getContent('stationlist.xml', filename=data_file)
            fault_files = shakemap.getContentsMatching('fault.txt')
            if len(fault_files):
                fault_file = os.path.join(event_dir, fault_files[0])
                shakemap.getContent(fault_files[0], filename=fault_file)
                xmlfile = os.path.join(event_dir, 'event.xml')
                jdict = text_to_json(fault_file, new_format=False)
                origin = Origin(edict)
                rupt = rupture_from_dict_and_origin(jdict, origin)
                _, ffile = os.path.split(fault_file)
                fbase, _ = os.path.splitext(ffile)
                jsonfile = os.path.join(event_dir, fbase+'.geojson')
                rupt.writeGeoJson(jsonfile)
                os.remove(fault_file)

            # if the user wanted to preserve the model parameters found in info.json, set those here
            if args.preserve_params:
                _write_model_conf(shakemap)

        print('Wrote %i files to %s.' %
              (len(os.listdir(event_dir)), event_dir))


def _write_model_conf(shakemap):
    info_json = shakemap.getContentBytes(
        'info.json').decode('utf-8')
    jsondict = json.loads(info_json)
    model = ConfigObj()
    model['modeling'] = {'bias': {}}
    bias_max_mag = jsondict['processing']['miscellaneous']['bias_max_mag']
    max_range = jsondict['processing']['miscellaneous']['bias_max_range']
    if bias_max_mag > 0 and max_range > 0:
        model['modeling']['bias']['do_bias'] = True
        model['modeling']['bias']['max_range'] = max_range
        model['modeling']['bias']['max_mag'] = bias_max_mag
    else:
        model['modeling']['bias']['do_bias'] = False

    # get the outlier information
    model['data'] = {'outlier': {}}
    max_deviation = jsondict['processing']['miscellaneous']['outlier_deviation_level']
    outlier_max_mag = jsondict['processing']['miscellaneous']['outlier_max_mag']
    if outlier_max_mag > 0 and max_deviation > 0:
        model['data']['outlier']['do_outlier'] = True
        model['data']['outlier']['max_deviation'] = max_deviation
        model['data']['outlier']['max_mag'] = outlier_max_mag
    else:
        model['data']['outlier']['do_outlier'] = False

    # get the gmice stuff
    allowed_gmice = module_conf['gmice_modules'].keys()
    gmice = jsondict['processing']['ground_motion_modules']['mi2pgm']['module']
    # WGRW11 in SM3.5 is WGRW12 in SM4.0
    if gmice == 'WGRW11':
        gmice = 'WGRW12'
    if gmice not in allowed_gmice:
        errors.append('GMICE %s (event %s) not yet supported in ShakeMap 4.' % (
            gmice, edict['id']))
    else:
        model['modeling']['gmice'] = gmice

    # work on map extent/resolution data
    if not skip_bounds:
        model['interp'] = {'prediction_location': {}}
        yres_km = jsondict['output']['map_information']['grid_spacing']['latitude']
        yres_sec = int(round(yres_km * KM2SEC))
        model['interp']['prediction_location']['xres'] = '%ic' % yres_sec
        model['interp']['prediction_location']['yres'] = '%ic' % yres_sec

    # set the bounds of the map, unless user asked to ignore that
    if not skip_bounds:
        model['extent'] = {'bounds': {}}
        xmin = jsondict['output']['map_information']['min']['longitude']
        xmax = jsondict['output']['map_information']['max']['longitude']
        ymin = jsondict['output']['map_information']['min']['latitude']
        ymax = jsondict['output']['map_information']['max']['latitude']
        model['extent']['bounds']['extent'] = [xmin, ymin, xmax, ymax]

    # done with model.conf, merge with existing file and save
    model_file = os.path.join(event_dir, 'model.conf')
    if os.path.isfile(model_file):
        existing_model = ConfigObj(model_file)
        model.merge(existing_model)
    model.filename = model_file
    model.write()


if __name__ == '__main__':
    parser = get_parser()
    pargs = parser.parse_args()
    main(pargs)
