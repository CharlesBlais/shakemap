#!/usr/bin/env python

# stdlib imports
import argparse
import os.path
import sys
import re
import glob
import logging
import tarfile
from xml.dom import minidom
import json

# third party imports
import pytz
from lxml import etree
from configobj import ConfigObj

# local imports
from shakemap.utils.config import get_config_paths, get_configspec
from shakemap.utils.utils import get_network_name
from shakemap.utils.amps import AmplitudeHandler
from shakelib.rupture.origin import read_event_file
from shakelib.rupture.factory import get_rupture
from impactutils.time.ancient_time import HistoricTime
import shakemap.utils.queue as queue
from shakemap.coremods import transfer

KM2SEC = 3600.0/111  # seconds per kilometer


def get_parser():
    description = '''Migrate existing ShakeMap 3.5 data directories.

    This program takes one required file, a tarball of one or more ShakeMap 3.5
    event directories.  To create this file, run a command like this:

    find . -name "*_dat.xml" -o -name "*_fault.txt" -o -name "source.txt" -o -name "info.json" -o -name "*.conf" | tar -czvf ~/sm35_inputs.tgz -T -

    '''
    parser = argparse.ArgumentParser(description=description,
                                     formatter_class=argparse.RawTextHelpFormatter)
    parser.add_argument('tarfile',
                        help='Input root data tarfile')
    hlptxt = '''Ignore directories where event_source (from model.conf)
does not prepend eventid'''
    parser.add_argument('-i', '--ignore-naked-ids', action='store_true', default=False,
                        help=hlptxt)
    hlptxt2 = '''Ignore previous bounds/resolution settings discovered
in input data.'''
    parser.add_argument('-s', '--skip-bounds', action='store_true', default=False,
                        help=hlptxt2)
    return parser


def main(args):
    install_path, data_path = get_config_paths()
    if not os.path.isdir(data_path):
        print('%s is not a valid directory.' % data_path)
        sys.exit(1)

    # get the system model.conf
    modelfile = os.path.join(install_path, 'config', 'model.conf')
    model_config = ConfigObj(modelfile)
    netid = model_config['system']['source_network']

    # get the system modules.conf file, which tells us about implemented
    # GMICE
    modulefile = os.path.join(install_path, 'config', 'modules.conf')
    module_conf = ConfigObj(modulefile)

    # We're going to be inserting these events in the database later
    handler = AmplitudeHandler(install_path, data_path)

    alleventids = []
    networks = {}

    unique_flags = []

    # loop over events in the input tarball
    tarball = tarfile.open(args.tarfile, mode='r:gz')
    for member in tarball.getnames():
        if 'save' in member:
            continue
        parts = member.split('/')
        filename = parts[-1]
        eventid = parts[-3]
        if eventid not in alleventids:
            print('Processing event %s...' % eventid)
            alleventids.append(eventid)

        if not eventid.startswith(netid):
            if args.ignore_naked_ids:
                # print('Skipping naked ID %s.' % eventid)
                continue
            else:
                eventid = netid + eventid

        event_dir = os.path.join(data_path, eventid, 'current')
        if not os.path.isdir(event_dir):
            event_dir = create_event_directory(eventid, data_path)

        if filename.endswith('.conf'):
            parse_config(event_dir, tarball, member)
        elif filename.endswith('_dat.xml'):
            tarball.extract(member, path=event_dir)
        elif filename.endswith('_fault.txt'):
            # I can't save this as a rupture json file until I know the origin info
            # fix after the fact?
            tarball.extract(member, path=event_dir)
        elif filename in ['info.json']:
            if 'download' in member:
                continue
            edict = save_info(event_dir, tarball, member,
                              netid, networks, module_conf, skip_bounds=args.skip_bounds)
            handler.insertEvent(edict)
        else:
            print('Unknown input file: %s' % filename)

    tarball.close()

    # go back through the data, convert fault.txt files into json rupture format,
    # also make sure we have all required components
    for eventid in alleventids:
        event_dir = os.path.join(data_path, eventid, 'current')
        make_rupture(event_dir)


def make_rupture(event_dir):
    fault_files = glob.glob('*_fault.txt')
    if not len(fault_files):
        return
    fault_file = fault_files[0]
    origin =


def parse_grind(event_dir, tarball, member):
    parts = member.split('/')
    eventid = parts[-3]
    grindfile = tarball.extractfile(member)
    lines = grindfile.readlines()
    gmpe_msg = '''gmpe setting of %s detected in event %s. Please read the documentation
on how to configure GMPEs for different depths and magnitude ranges in select.conf.
'''
    # model.conf
    model = ConfigObj()
    model['modeling'] = {}
    model['system'] = {}
    model['data'] = {'outlier': {}}

    for line in lines:
        line = line.decode('utf-8').strip()
        if line.strip().startswith('#'):
            continue
        if not len(line.strip()):
            continue
        key, value = line.split(':')
        key = key.strip()
        value = value.strip()
        if key == 'gmpe':
            print(gmpe_msg)
        elif key == 'ipe':
            print(gmpe_msg)
        elif key == 'mi2pgm' or key == 'pgm2mi':
            if value == 'WGRW11':
                value = 'WGRW12'
            model['modeling']['gmice'] = value
        elif key == 'outlier_deviation_level':
            model['data']['outlier']['max_deviation'] = value
        elif key == 'max_mag':
            model['data']['outlier']['max_mag'] = value
        elif key == 'source_network':
            model['system']['source_network'] = value

    model_file = os.path.join(event_dir, 'model.conf')
    if os.path.isfile(model_file):
        existing_model = ConfigObj(model_file)
        model.merge(existing_model)
    model.filename = model_file
    model.write()


def parse_transfer(event_dir, tarball, member):
    parts = member.split('/')
    eventid = parts[-3]
    grindfile = tarball.extractfile(member)
    lines = grindfile.readlines()
    for line in lines:
        if line.strip*().startswith('#'):
            continue
        if not len(line.strip()):
            continue
        if 'pdl_config' in line:
            # this applies to the installation at NEIC
            # more knowledge of regional SM installations is required
            if 'ehpdev' in line:
                notransfer = os.path.join(event_dir, transfer.NO_TRANSFER)
                with open(notransfer, 'wt') as f:
                    f.write('transfer blocked by sm_migrate.')


def parse_config(event_dir, tarball, member):
    if 'shake.conf' in member:
        pass
    elif 'grind_zc2.conf' in member:
        pass
    elif 'grind.conf' in member:
        parse_grind(event_dir, tarball, member)
    elif 'db.conf' in member:
        pass
    elif 'timezone.conf':
        pass
    elif 'retrieve.conf' in member:
        pass
    elif 'transfer.conf' in member:
        parse_transfer(event_dir, tarball, member)
    else:
        print('Unknown config file type %s' % member)


def save_info(event_dir, tarball, member, netid, networks,
              module_conf, skip_bounds=False):
    jsonfile = tarball.extractfile(member)
    jsonstring = jsonfile.read().decode('utf-8')
    jsondict = json.loads(jsonstring)

    # get the origin information out of the json
    xmlfile = os.path.join(event_dir, 'event.xml')
    root = etree.Element('earthquake')
    root.attrib['id'] = jsondict['input']['event_information']['event_id']
    timestring = jsondict['input']['event_information']['origin_time'][0:19]+'.000Z'
    root.attrib['time'] = timestring
    root.attrib['netid'] = netid
    if netid in networks:
        root.attrib['network'] = networks[netid]
    else:
        network = get_network_name(netid)
        if network == 'unknown':
            network = ''
        networks[netid] = network
        root.attrib['network'] = network
    root.attrib['lat'] = '%.4f' % jsondict['input']['event_information']['latitude']
    root.attrib['lon'] = '%.4f' % jsondict['input']['event_information']['longitude']
    root.attrib['depth'] = '%.1f' % jsondict['input']['event_information']['depth']
    root.attrib['mag'] = '%.1f' % jsondict['input']['event_information']['magnitude']
    root.attrib['locstring'] = jsondict['input']['event_information']['location']
    root.attrib['mech'] = jsondict['input']['event_information']['src_mech']
    tree = etree.ElementTree(root)
    tree.write(xmlfile, pretty_print=True)

    # get the above info as an amps.db event dictionary
    edict = {'id': root.attrib['id'],
             'netid': root.attrib['netid'],
             'network': root.attrib['network'],
             'time': root.attrib['time'],
             'lat': root.attrib['lat'],
             'lon': root.attrib['lon'],
             'depth': root.attrib['depth'],
             'mag': root.attrib['mag'],
             'location': root.attrib['locstring']}

    # get all of the bias information
    model = ConfigObj()
    model['modeling'] = {'bias': {}}
    bias_max_mag = jsondict['processing']['miscellaneous']['bias_max_mag']
    max_range = jsondict['processing']['miscellaneous']['bias_max_range']
    if bias_max_mag > 0 and max_range > 0:
        model['modeling']['bias']['do_bias'] = True
        model['modeling']['bias']['max_range'] = max_range
        model['modeling']['bias']['max_mag'] = bias_max_mag
    else:
        model['modeling']['bias']['do_bias'] = False

    # get the outlier information
    model['data'] = {'outlier': {}}
    max_deviation = jsondict['processing']['miscellaneous']['outlier_deviation_level']
    outlier_max_mag = jsondict['processing']['miscellaneous']['outlier_max_mag']
    if outlier_max_mag > 0 and max_deviation > 0:
        model['data']['outlier']['do_outlier'] = True
        model['data']['outlier']['max_deviation'] = max_deviation
        model['data']['outlier']['max_mag'] = outlier_max_mag
    else:
        model['data']['outlier']['do_outlier'] = False

    # get the gmice stuff
    allowed_gmice = module_conf['gmice_modules'].keys()
    gmice = jsondict['processing']['ground_motion_modules']['mi2pgm']['module']
    # WGRW11 in SM3.5 is WGRW12 in SM4.0
    if gmice == 'WGRW11':
        gmice = 'WGRW12'
    if gmice not in allowed_gmice:
        sys.stderr.write('GMICE %s not yet supported in ShakeMap 4.' % gmice)
    else:
        model['modeling']['gmice'] = gmice

    # work on map extent/resolution data
    if not skip_bounds:
        model['interp'] = {'prediction_location': {}}
        yres_km = jsondict['output']['map_information']['grid_spacing']['latitude']
        yres_sec = int(round(yres_km * KM2SEC))
        model['interp']['prediction_location']['xres'] = '%ic' % yres_sec
        model['interp']['prediction_location']['yres'] = '%ic' % yres_sec

    # done with model.conf, merge with existing file and save
    model_file = os.path.join(event_dir, 'model.conf')
    if os.path.isfile(model_file):
        existing_model = ConfigObj(model_file)
        model.merge(existing_model)
    model.filename = model_file
    model.write()

    # modify extent.conf
    if not skip_bounds:
        extent = ConfigObj()
        extent['extent'] = {'bounds': {}}
        xmin = jsondict['output']['map_information']['min']['longitude']
        xmax = jsondict['output']['map_information']['max']['longitude']
        ymin = jsondict['output']['map_information']['min']['latitude']
        ymax = jsondict['output']['map_information']['max']['latitude']
        extent['extent']['bounds']['extent'] = [xmin, ymin, xmax, ymax]

        # done with extent.conf, merge with existing file and save
        extent_file = os.path.join(event_dir, 'extent.conf')
        if os.path.isfile(extent_file):
            existing_extent = ConfigObj(extent_file)
            extent.merge(existing_extent)
        extent.filename = extent_file
        extent.write()

    return edict


def create_event_directory(eventid, data_path):
    event_dir = os.path.join(data_path, eventid, 'current')
    if os.path.isdir(event_dir):
        return None
    os.makedirs(event_dir)
    return event_dir


if __name__ == '__main__':
    parser = get_parser()
    pargs, unknown = parser.parse_known_args()
    main(pargs)
